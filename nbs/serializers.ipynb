{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a34957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp serializers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34f38641",
   "metadata": {},
   "source": [
    "# Serializers\n",
    "> Various utilities to encode MARIS dataset as `NetCDF`, `csv`, ... formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27051f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4934cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Callable\n",
    "import pandas as pd\n",
    "from fastcore.basics import patch, store_attr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f835f92",
   "metadata": {},
   "source": [
    "### NetCDFEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e31b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NetCDFEncoder:\n",
    "    \"MARIS NetCDF encoder.\"\n",
    "    def __init__(self, \n",
    "                 dfs:dict[pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "                 src_fname:str, # File name and path to the MARIS CDL template\n",
    "                 dest_fname:str, # Name of output file to produce\n",
    "                 global_attrs:Dict, # Global attributes\n",
    "                 enums_xtra:Dict={}, # Enumeration types to overwrite\n",
    "                 verbose:bool=False, # Print currently written NetCDF group and variable names\n",
    "                 ):\n",
    "        store_attr()\n",
    "        self.enum_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "584f9d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seawater = pd.DataFrame({\n",
    "    'sample': [0, 1, 5], \n",
    "    'lon': [141, 142, 143], \n",
    "    'lat': [37.3, 38.3, 39.3], \n",
    "    'time': [1234, 1235, 1236], \n",
    "    'i131': [1, 1.5, 2],\n",
    "    'i131_dl': [0, 1, 2], \n",
    "    'i131_unit': [1, 1, 2],\n",
    "    'species_id': [134, 136, 137]\n",
    "    })\n",
    "\n",
    "df_biota = pd.DataFrame({\n",
    "    'sample': [0, 1], \n",
    "    'lon': [141, 142], \n",
    "    'lat': [37.3, 38.3], \n",
    "    'time': [1234, 1235], \n",
    "    'i131': [1, 1.5],\n",
    "    'i131_dl': [0, 1], \n",
    "    'i131_unit': [1, 1],\n",
    "    'species_id': [134, 136]\n",
    "    })\n",
    "dfs = {'seawater': df_seawater, 'biota': df_biota}\n",
    "attrs = {'id': '123', 'title': 'Test title', 'summary': 'Summary test'}\n",
    "src = './files/nc/template-test.nc'\n",
    "dest = './files/nc/encoding-test.nc'\n",
    "enums_xtra = {\n",
    "    'species_t': {'Aristeus antennatus': 134, 'Apostichopus': 136}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd3f1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NetCDFEncoder(dfs, src_fname=src, dest_fname=dest, global_attrs=attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7beed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch \n",
    "def copy_global_attributes(self:NetCDFEncoder):\n",
    "    \"Update NetCDF template global attributes as specified by `global_attrs` argument.\"\n",
    "    self.dest.setncatts(self.src.__dict__)\n",
    "    for k, v in self.global_attrs.items(): self.dest.setncattr(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30e7f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_dimensions(self:NetCDFEncoder):\n",
    "    for name, dimension in self.src.dimensions.items():\n",
    "        self.dest.createDimension(name, (len(dimension) if not dimension.isunlimited() else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e24da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_groups(self:NetCDFEncoder):\n",
    "    for grp_name, df in self.dfs.items():\n",
    "        self.process_group(grp_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e308b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_group(self:NetCDFEncoder, group_name, df):\n",
    "    group_dest = self.dest.createGroup(group_name)\n",
    "    # Set the dimensions for each group\n",
    "    group_dest.createDimension(group_name, len(df.index))\n",
    "    self.copy_variables(group_name, df, group_dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61ef40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variables(self:NetCDFEncoder, group_name, df, group_dest):\n",
    "    for var_name, var_src in self.src.groups[group_name].variables.items():\n",
    "        if var_name in df.reset_index().columns: \n",
    "            self.copy_variable(var_name, var_src, df, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40561907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variable(self:NetCDFEncoder, var_name, var_src, df, group_dest):\n",
    "    dtype_name = var_src.datatype.name\n",
    "    enums_src = self.src.enumtypes\n",
    "    if self.verbose: print(f'Group: {group_dest.name}, Variable: {var_name}')\n",
    "    # if the type of the var is an enum (meaning present in the template src) then create it\n",
    "    if dtype_name in enums_src: self.copy_enum_type(dtype_name)   \n",
    "    self._create_and_copy_variable(var_name, var_src, df, group_dest, dtype_name)\n",
    "    self.copy_variable_attributes(var_name, var_src, group_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93792604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def _create_and_copy_variable(self:NetCDFEncoder, var_name, var_src, df, group_dest, dtype_name):\n",
    "    variable_type = self.enum_types.get(dtype_name, var_src.datatype)\n",
    "    # use the group_dest dimensions\n",
    "    group_dest.createVariable(var_name, variable_type, group_dest.dimensions, compression='zlib', complevel=9)    \n",
    "    df_sanitized = self.cast_verbose_rf(df, var_name)\n",
    "    group_dest[var_name][:] = df_sanitized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efd48f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_enum_type(self:NetCDFEncoder, dtype_name):\n",
    "    # if enum type not already created\n",
    "    if dtype_name not in self.enum_types:\n",
    "        enum_info = self.src.enumtypes[dtype_name]\n",
    "        # if a subset of an enum is defined in enums_xtra (typically for the lengthy species_t)\n",
    "        if enum_info.name in self.enums_xtra:\n",
    "            enum_info.enum_dict = self.enums_xtra[enum_info.name]\n",
    "        self.enum_types[dtype_name] = self.dest.createEnumType(enum_info.dtype, \n",
    "                                                               enum_info.name, \n",
    "                                                               enum_info.enum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6068704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def copy_variable_attributes(self:NetCDFEncoder, var_name, var_src, group_dest):\n",
    "    group_dest[var_name].setncatts(var_src.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf24f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def cast_verbose_rf(self:NetCDFEncoder, \n",
    "                    df, \n",
    "                    col):\n",
    "    \"\"\"\n",
    "    Try to cast df column to numeric type:\n",
    "        - Silently coerce to nan if not possible\n",
    "        - But log when it failed\n",
    "    \"\"\"\n",
    "    n_before = sum(df.reset_index()[col].notna())\n",
    "    df_after = pd.to_numeric(df.reset_index()[col],\n",
    "                                    errors='coerce', downcast=None)\n",
    "    n_after = sum(df_after.notna())\n",
    "    if n_before != n_after: \n",
    "        print(f'Failed to convert type of {col} in {n_before - n_after} occurences')\n",
    "    \n",
    "    return df_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20edc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def encode(self:NetCDFEncoder):\n",
    "    \"Encode MARIS NetCDF based on template and dataframes.\"\n",
    "    with Dataset(self.src_fname, format='NETCDF4') as self.src, Dataset(self.dest_fname, 'w', format='NETCDF4') as self.dest:\n",
    "        self.copy_global_attributes()\n",
    "        self.copy_dimensions()\n",
    "        self.process_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6759d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NetCDFEncoder(dfs, src_fname=src, dest_fname=dest, global_attrs=attrs, verbose=False)\n",
    "encoder.encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5881d1b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92e35c",
   "metadata": {},
   "source": [
    "### OpenRefineCsvEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50ab6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OpenRefineCsvEncoder:\n",
    "    \"OpenRefine CSV from NetCDF.\"\n",
    "    def __init__(self, \n",
    "                 dfs:dict[pd.DataFrame], # dict of Dataframes to encode with group name as key {'sediment': df_sed, ...}\n",
    "                 dest_fname:str, # Name of output file to produce\n",
    "                 verbose:bool=False, # Print \n",
    "                 ):\n",
    "        store_attr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d52a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_groups_to_csv(self:OpenRefineCsvEncoder):\n",
    "    for grp_name, df in self.dfs.items():\n",
    "        self.process_group_to_csv(grp_name, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daee7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def process_group_to_csv(self:OpenRefineCsvEncoder, group_name, df):\n",
    "    filename, file_extension=os.path.splitext(self.dest_fname)\n",
    "    path = filename + '_' + group_name + file_extension\n",
    "    df.to_csv ( path_or_buf= path, sep=',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "455f41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def encode(self:OpenRefineCsvEncoder):\n",
    "    \"Encode OpenRefine CSV based on dataframes from NetCDF.\"\n",
    "    self.process_groups_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "719aa378",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = '../files/csv/encoding-test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6b58932",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OpenRefineCsvEncoder(dfs,  dest_fname=dest)\n",
    "encoder.encode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
